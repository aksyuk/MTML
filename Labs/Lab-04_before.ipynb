{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1aef29b",
   "metadata": {},
   "source": [
    "`Дисциплина: Методы и технологии машинного обучения`   \n",
    "`Уровень подготовки: бакалавриат`   \n",
    "`Направление подготовки: 01.03.02 Прикладная математика и информатика`   \n",
    "`Семестр: осень 2021/2022`   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Лабораторная работа №4: Методы снижения размерности. Регуляризация логистической регрессии. \n",
    "\n",
    "В практических примерах ниже показано:   \n",
    "\n",
    "* как снижать размерность пространства признаков методами главных компонент (PCR), частных наименьшах квадратов (PLS)  \n",
    "* как строить логистическую регрессию с регуляризацией параметров (методы ридж и лассо) \n",
    "\n",
    "Точность всех моделей оценивается методом перекрёстной проверки по 10 блокам.  \n",
    "\n",
    "*Модели*: множественная линейная регрессия \n",
    "*Данные*: `Wines` (источник: [репозиторий к книге С.Рашки Python и машинное обучение, глава 4](https://github.com/rasbt/python-machine-learning-book-3rd-edition/tree/master/ch04))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9ab5d",
   "metadata": {},
   "source": [
    "# Указания к выполнению\n",
    "\n",
    "\n",
    "## Загружаем пакеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка пакетов: инструменты --------------------------------------------\n",
    "#  работа с массивами\n",
    "import numpy as np\n",
    "#  фреймы данных\n",
    "import pandas as pd\n",
    "#  распределение Стьюдента для проверки значимости\n",
    "from scipy.stats import t\n",
    "# подсчёт частот внутри массива\n",
    "from collections import Counter\n",
    "#  графики\n",
    "import matplotlib as mpl\n",
    "#  стили и шаблоны графиков на основе matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# загрузка пакетов: данные -------------------------------------------------\n",
    "from sklearn import datasets\n",
    "\n",
    "# загрузка пакетов: модели -------------------------------------------------\n",
    "#  стандартизация показателей\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#  метод главных компонент\n",
    "from sklearn.decomposition import PCA\n",
    "# метод частных наименьших квадратов\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "#  логистическая регрессия (ММП)\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "#  перекрёстная проверка по k блокам\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "#  расчёт Acc и сводка по точности классификации\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# константы\n",
    "#  ядро для генератора случайных чисел\n",
    "my_seed = 9212\n",
    "#  создаём псевдоним для короткого обращения к графикам\n",
    "plt = mpl.pyplot\n",
    "# настройка стиля и отображения графиков\n",
    "#  примеры стилей и шаблонов графиков: \n",
    "#  http://tonysyu.github.io/raw_content/matplotlib-style-gallery/gallery.html\n",
    "mpl.style.use('seaborn-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "# раскомментируйте следующую строку, чтобы посмотреть палитру\n",
    "# sns.color_palette(\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d97f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция, которая строит график сжатия коэффициентов в ридж и лассо\n",
    "#  из репозитория к книге С.Рашки Python и машинное обучение,\n",
    "#  слегка переработанная\n",
    "def plot_coeffs_traces (X, y, class_number, penalty_name, C_opt, col_names,\n",
    "                        C_min_pow=-4, C_max_pow=3.) :\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)    \n",
    "    \n",
    "    # палитра\n",
    "    colors = sns.color_palette(\"Spectral\", len(col_names)-1)\n",
    "    \n",
    "    weights, params = [], []\n",
    "    for c in np.arange(C_min_pow, C_max_pow+1):\n",
    "        lr = LogisticRegression(penalty=penalty_name, \n",
    "                                C=10.**c, solver='liblinear', \n",
    "                                multi_class='ovr', random_state=my_seed)\n",
    "        lr.fit(X, y)\n",
    "        weights.append(lr.coef_[class_number])\n",
    "        params.append(10**c)\n",
    "\n",
    "    weights = np.array(weights)\n",
    "\n",
    "    for column, color in zip(range(weights.shape[1]), colors):\n",
    "        plt.plot(params, weights[:, column],\n",
    "                 label=col_names[column],\n",
    "                 color=color)\n",
    "\n",
    "    # отсечки по оптимальным C\n",
    "    plt.axvline(x=C_opt[class_number], color='magenta', \n",
    "                linestyle='--', linewidth=1)\n",
    "\n",
    "    plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.xlim([10**(C_min_pow), 10**C_max_pow])\n",
    "    plt.ylabel('weight coefficient')\n",
    "    plt.xlabel('C')\n",
    "    plt.xscale('log')\n",
    "    plt.legend(loc='upper left')\n",
    "    ax.legend(loc='upper center', \n",
    "              bbox_to_anchor=(1.38, 1.03),\n",
    "              ncol=1, fancybox=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87618f1b",
   "metadata": {},
   "source": [
    "## Загружаем данные\n",
    "\n",
    "Набор данных `wine` можно загрузить напрямую из пакета `sklearn` (набор впервые выложен [на сайте Калифорнийского университета в Ирвине](http://archive.ics.uci.edu/ml/datasets/Wine)). Таблица содержит результаты химического анализа вин, выращенных в одном регионе Италии тремя разными производителями. Большинство столбцов таблицы отражают содержание в вине различных веществ:   \n",
    "\n",
    "* `alcohol` – алкоголь, процентное содержание;  \n",
    "* `malic_acid` – яблочная кислота (разновидность кислоты с сильной кислотностью и ароматом яблока);  \n",
    "* `ash` – зола (неорганическая соль, оказывающая влияние на вкус и придающая вину ощущение свежести);  \n",
    "* `alcalinity_of_ash` – щелочность золы;  \n",
    "* `magnesium` – магний (важный для организма слабощелочной элемент, способствующий энергетическому обмену);  \n",
    "* `total_phenols` – всего фенола (молекулы, содержащие полифенольные вещества; имеют горький вкус, также влияют на цвет, относятся к питательным веществам в вине);  \n",
    "* `flavanoids` – флаваноиды (полезный антиоксидант, даёт богатый аромат и горький вкус);  \n",
    "* `nonflavanoid_phenols` – фенолы нефлаваноидные (специальный ароматический газ, устойчивый к окислению);  \n",
    "* `proanthocyanins` – проантоцианы (биофлавоноидное соединение, которое также является природным антиоксидантом с легким горьковатым запахом); \n",
    "* `color_intensity` – интенсивность цвета; \n",
    "* `hue` – оттенок (мера яркости цвета, используется в т.ч. для измерения возраста вина); \n",
    "* `od280/od315_of_diluted_wines` – OD280/OD315 разбавленных вин (метод определения концентрации белка); \n",
    "* `proline` – пролин (основная аминокислота в красном вине, важный фактор вкуса и аромата); \n",
    "* `target` – целевая переменная: класс вина.   \n",
    "\n",
    "Загружаем данные во фрейм и выясняем их размерность.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e42f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем таблицу и превращаем её во фрейм\n",
    "DF_all = \n",
    "\n",
    "# выясняем размерность фрейма\n",
    "print('Число строк и столбцов в наборе данных:\\n', DF_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7ffd1",
   "metadata": {},
   "source": [
    "Отложим 10% наблюдений для прогноза.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f9300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# наблюдения для моделирования\n",
    "DF = \n",
    "# отложенные наблюдения\n",
    "DF_predict = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2eedc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# первые 5 строк фрейма у первых 7 столбцов\n",
    "DF.iloc[:, :7].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ca5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# первые 5 строк фрейма у столбцов 8-11\n",
    "DF.iloc[:, 7:11].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# первые 5 строк фрейма у столбцов 12-14\n",
    "DF.iloc[:, 11:].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e97a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# типы столбцов фрейма\n",
    "DF.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a540a2",
   "metadata": {},
   "source": [
    "Проверим, нет ли в таблице пропусков.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a96cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем пропуски в каждом столбце\n",
    "DF.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2941191c",
   "metadata": {},
   "source": [
    "Пропусков не обнаружено.  \n",
    "\n",
    "# Предварительный анализ данных  \n",
    "\n",
    "## Описательные статистики  \n",
    "\n",
    "Считаем доли классов целевой переменной `target`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# метки классов\n",
    "DF.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# доли классов\n",
    "np.around(DF.target.value_counts() / len(DF.index), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3216487",
   "metadata": {},
   "source": [
    "Все объясняющие переменные набора данных непрерывные. Рассчитаем для них описательные статистики.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# описательные статистики\n",
    "DF.iloc[:, :6].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ba2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# описательные статистики\n",
    "DF.iloc[:, 6:11].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# описательные статистики\n",
    "DF.iloc[:, 11:13].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe7bbef",
   "metadata": {},
   "source": [
    "Выводы по описательным статистикам: значения объясняющих переменных положительные, масштабы измерения отличаются. Для работы с методами снижения размерности и регуляризации понадобится стандартизация значений.   \n",
    "\n",
    "## Визуализация разброса переменных внутри классов  \n",
    "\n",
    "Поскольку в наборе данных 13 объясняющих переменных, и все они непрерывные, анализ матричного графика разброса будет затруднительным. Построим коробчатые диаграммы для объясняющих переменных, чтобы сравнить средние уровни и разброс по классам.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём полотно и делим его на четыре части\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "gs = mpl.gridspec.GridSpec(1, 5)\n",
    "ax1 = plt.subplot(gs[0, 0])\n",
    "ax2 = plt.subplot(gs[0, 1])\n",
    "ax3 = plt.subplot(gs[0, 2])\n",
    "ax4 = plt.subplot(gs[0, 3])\n",
    "ax5 = plt.subplot(gs[0, 4])\n",
    "\n",
    "axs = [ax1, ax2, ax3, ax4, ax5]\n",
    "\n",
    "cols_loop = \n",
    "for col_name in cols_loop :\n",
    "    i = \n",
    "    sns.boxplot(x=, y=, data=DF, ax=axs[i])\n",
    "    axs[i].set_ylabel(col_name)\n",
    "    axs[i].set_title(col_name)\n",
    "\n",
    "# корректируем расположение графиков на полотне\n",
    "gs.tight_layout(plt.gcf())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af48928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём полотно и делим его на четыре части\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "gs = mpl.gridspec.GridSpec(1, 5)\n",
    "ax1 = plt.subplot(gs[0, 0])\n",
    "ax2 = plt.subplot(gs[0, 1])\n",
    "ax3 = plt.subplot(gs[0, 2])\n",
    "ax4 = plt.subplot(gs[0, 3])\n",
    "ax5 = plt.subplot(gs[0, 4])\n",
    "\n",
    "axs = [ax1, ax2, ax3, ax4, ax5]\n",
    "\n",
    "cols_loop = \n",
    "for col_name in cols_loop :\n",
    "    i = cols_loop.index(col_name)\n",
    "    sns.boxplot(x='target', y=col_name, data=DF, ax=axs[i])\n",
    "    axs[i].set_ylabel(col_name)\n",
    "    axs[i].set_title(col_name)\n",
    "\n",
    "# корректируем расположение графиков на полотне\n",
    "gs.tight_layout(plt.gcf())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742bbdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём полотно и делим его на четыре части\n",
    "fig = plt.figure(figsize=(7.2, 5))\n",
    "gs = mpl.gridspec.GridSpec(1, 3)\n",
    "ax1 = plt.subplot(gs[0, 0])\n",
    "ax2 = plt.subplot(gs[0, 1])\n",
    "ax3 = plt.subplot(gs[0, 2])\n",
    "\n",
    "axs = [ax1, ax2, ax3]\n",
    "\n",
    "cols_loop = list(DF.columns[10:13].values)\n",
    "for col_name in cols_loop :\n",
    "    i = cols_loop.index(col_name)\n",
    "    sns.boxplot(x='target', y=col_name, data=DF, ax=axs[i])\n",
    "    axs[i].set_ylabel(col_name)\n",
    "    axs[i].set_title(col_name)\n",
    "\n",
    "# корректируем расположение графиков на полотне\n",
    "gs.tight_layout(plt.gcf())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e9584f",
   "metadata": {},
   "source": [
    "На графиках отличие в медианах и разбросе между классами прослеживается практически по всем объясняющим переменным. Меньше всего различаются коробчатые диаграммы по переменной `ash`. Это говорит о том, классы по зависимой переменной `target` неплохо разделяются по всем объясняющим переменным.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7542b",
   "metadata": {},
   "source": [
    "## Корреляционный анализ   \n",
    "\n",
    "Теперь посмотрим на взаимодействие объясняющих переменных.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассчитываем корреляционную матрицу\n",
    "corr_mat = \n",
    "col_names = \n",
    "\n",
    "# переключаем стиль оформления, чтобы убрать сетку с тепловой карты\n",
    "mpl.style.use('seaborn-white')\n",
    "\n",
    "# рисуем корреляционную матрицу\n",
    "f = plt.figure(figsize=(10, 8))\n",
    "plt.matshow(corr_mat, fignum=f.number, cmap='PiYG')\n",
    "# координаты для названий строк и столбцов\n",
    "tics_coords = np.arange(0, len(col_names))\n",
    "# рисуем подписи\n",
    "plt.xticks(tics_coords, col_names, fontsize=14, rotation=90)\n",
    "plt.yticks(tics_coords, col_names, fontsize=14)\n",
    "# настраиваем легенду справа от тепловой карты\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47250c6",
   "metadata": {},
   "source": [
    "Между объясняющими переменными обнаруживаются как прямые, так и обратные линейные взаимосвязи. Выведем все значимые коэффициенты в одной таблице и определим минимальный / максимальный из них.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf56e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем фрейм из корреляционной матрицы и стираем диагональные значения\n",
    "#  и нижний треугольник матрицы\n",
    "df = \n",
    "df = \n",
    "# меняем размерность с матрицы на таблицу: показатель 1, показатель 2,\n",
    "#  корреляция\n",
    "df = \n",
    "df.columns = ['Показатель_1', 'Показатель_2', 'Корреляция']\n",
    "# считаем двусторонние p-значения для проверки значимости\n",
    "t_stat = \n",
    "df['P_значение'] = \n",
    "# получили все корреляционные коэффициенты без 1 и без повторов\n",
    "#  выводим все значимые с сортировкой\n",
    "df.loc[df['P_значение'] < 0.05].sort_values('Корреляция')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a48810",
   "metadata": {},
   "source": [
    "# Методы снижения резмерности  \n",
    "\n",
    "Посмотрим, как работают методы снижения размерности:  \n",
    "\n",
    "* регрессия на главные компоненты (PCR)   \n",
    "* частный метод наименьших квадратов (PLS)  \n",
    "\n",
    "Оба метода требуют предварительной стандартизации переменных.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688312d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# стандартизация\n",
    "sc = StandardScaler()\n",
    "X_train_std = \n",
    "\n",
    "# проверяем средние и стандартные отклонения после стандартизации\n",
    "for i_col in range(X_train_std.shape[1]) :\n",
    "    print('Столбец ', i_col, ': среднее = ',\n",
    "          np.round(np.mean(X_train_std[:, i_col]), 2),\n",
    "         '   Станд. отклонение = ', \n",
    "          np.round(np.std(X_train_std[:, i_col]), 2), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a0c22",
   "metadata": {},
   "source": [
    "## Регрессия на главные компоненты (PCR)  \n",
    "\n",
    "Пересчитаем объясняющие показатели в главные компоненты.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e2e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция с методом главных компонент\n",
    "pca = PCA()\n",
    "# пересчитываем в главные компоненты (ГК)\n",
    "X_train_pca = \n",
    "\n",
    "# считаем доли объяснённой дисперсии\n",
    "frac_var_expl = \n",
    "print('Доли объяснённой дисперсии по компонентам в PLS:\\n',\n",
    "     np.around(frac_var_expl, 3),\n",
    "     '\\nОбщая сумма долей:', np.around(sum(frac_var_expl), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae90980",
   "metadata": {},
   "source": [
    "Главные компоненты взаимно ортогональны, убедимся в этом.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba52a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ГК ортогональны – убедимся в этом, рассчитыв корреляционную матрицу\n",
    "corr_mat = pd.DataFrame(X_train_pca).corr()\n",
    "np.around(corr_mat, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d9327f",
   "metadata": {},
   "source": [
    "Построим график объяснённой дисперсии. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18370b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# график объяснённой дисперсии\n",
    "plt.bar(range(1, 14), pca.explained_variance_ratio_, alpha=0.5, \n",
    "        align='center', label='индивидуальная')\n",
    "plt.step(range(1, 14), np.cumsum(pca.explained_variance_ratio_), \n",
    "         where='mid', label='накопленная')\n",
    "plt.ylabel('Доля объяснённой дисперсии')\n",
    "plt.xlabel('Главные компоненты')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b8f0b9",
   "metadata": {},
   "source": [
    "Столбцы на графике показывают долю исходной дисперсии исходных переменных, которую объясняет главная компонента. Линией показана накопленная доля. Так, видно, что первые 5 компонент объясняют 80% исходной дисперсии $X$.   \n",
    "Чтобы увидеть, как классы выглядят в координатах ГК на графике, придётся сократить пространство для двух компонент, которые объясняют 56% разброса объясняющих переменных.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пересчитываем X в 2 ГК\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "\n",
    "# график классов в пространстве ГК\n",
    "plt.scatter(, \n",
    "            , label='target: 0')\n",
    "plt.scatter(, \n",
    "            , label='target: 1')\n",
    "plt.scatter(, \n",
    "            , label='target: 2')\n",
    "plt.xlabel('ГК 1 по PCA')\n",
    "plt.ylabel('ГК 2 по PCA')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d8d88",
   "metadata": {},
   "source": [
    "Судя по графику, классы неплохо разделяются в пространстве двух главных компонент. Построим логистическую регрессию и оценим её точность с помощью перекрёстной проверки.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf76589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция оценки логистической регрессии\n",
    "logit = LogisticRegression()\n",
    "# функция разбиения на блоки для перекрёстной проверки\n",
    "kf_10 = \n",
    "# считаем точность модели (Acc) с перекрёстной проверкой по блокам\n",
    "score = list()\n",
    "acc = \n",
    "\n",
    "score.append(np.around(acc, 3))\n",
    "score_models = list()\n",
    "score_models.append('logit_PC2')\n",
    "print('Модель ', score_models[0], ', перекрёстная проверка по 10 блокам',\n",
    "      '\\nAcc = ', np.around(score[0], 2), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c555295",
   "metadata": {},
   "source": [
    "## Метод частных наименьших квадратов  \n",
    "\n",
    "Сначала посмотрим, как работает метод на всех наблюдениях обучающего набора.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для оценки модели, берём все компоненты, по числу столбцов X\n",
    "pls = PLSRegression(n_components=13)\n",
    "# значения зависимой переменной превращаем в фиктивные по классам\n",
    "Y_train = \n",
    "# оцениваем\n",
    "\n",
    "\n",
    "# считаем долю объяснённой дисперсии\n",
    "frac_var_expl = \n",
    "print('Доли объяснённой дисперсии по компонентам в PLS:\\n',\n",
    "     np.around(frac_var_expl, 3),\n",
    "     '\\nОбщая сумма долей:', np.around(sum(frac_var_expl), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5753d89",
   "metadata": {},
   "source": [
    "Из-за того, что при вычислении компонент метдом PLS мы учитываем корреляцию с $Y$, компоненты, во-первых, не ортогональны, а во-вторых сумма объяснённых долей дисперсии уже не равняется 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e6c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сокращаем пространство компонент до 2\n",
    "pls = PLSRegression(n_components=2)\n",
    "# перестраиваем модель\n",
    "pls.fit(X_train_std, Y_train)\n",
    "# пересчитываем X\n",
    "X_train_pls = \n",
    "# предсказываем принадлежности классов для обучающего набора\n",
    "Y_train_pred = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee36387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вычисляем классы\n",
    "Y_train_hat = \n",
    "for y_i in Y_train_pred : \n",
    "    \n",
    "\n",
    "# сколько наблюдений попали в каждый класс по модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd7c05e",
   "metadata": {},
   "source": [
    "Рисуем классы на графике в координатах 2 главных компонент по PLS.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf167983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# график классов в пространстве ГК\n",
    "plt.scatter(X_train_pls[DF['target'] == 0][:, 0], \n",
    "            X_train_pls[DF['target'] == 0][:, 1], label='target: 0')\n",
    "plt.scatter(X_train_pls[DF['target'] == 1][:, 0], \n",
    "            X_train_pls[DF['target'] == 1][:, 1], label='target: 1')\n",
    "plt.scatter(X_train_pls[DF['target'] == 2][:, 0], \n",
    "            X_train_pls[DF['target'] == 2][:, 1], label='target: 2')\n",
    "plt.xlabel('ГК 1 по PLS')\n",
    "plt.ylabel('ГК 2 по PLS')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360f1b8",
   "metadata": {},
   "source": [
    "Видно, что в координатах двух компонент, рассчитанных методом частных наименьших квадратов, классы также оказываются хорошо разделимы.  \n",
    "Теперь оценим точность модели с перекрёстной проверкой.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f9f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция разбиения на блоки для перекрёстной проверки\n",
    "#  для чистоты эксперимента возьмём другое ядро генератора случайных чисел\n",
    "kf_10 = KFold(n_splits=10, random_state=my_seed+1, shuffle=True)\n",
    "# считаем точность модели (Acc) с перекрёстной проверкой по блокам\n",
    "#  функция cross_val_score не сработает, т.к. у нас мультиклассовая\n",
    "#  классификация, поэтому делаем вручную\n",
    "# значения Y как метки классов\n",
    "Y_train = \n",
    "# значения Y как фиктивные переменные\n",
    "Y_train_dummy = \n",
    "# модель внутри блока\n",
    "pls_cv = PLSRegression(n_components=2)\n",
    "# для записи Acc по блокам\n",
    "acc_blocks = list()\n",
    "# цикл по блокам\n",
    "for train_index, test_index in kf_10.split(X_train_std, DF.target.values) : \n",
    "    # данные для модели внутри блока\n",
    "    X_i_train = \n",
    "    Y_i_train = \n",
    "\n",
    "    # данные для прогноза вне блока\n",
    "    X_i_test = \n",
    "    Y_i_test = \n",
    "\n",
    "    # оцениваем модель на блоке\n",
    "    \n",
    "    # делаем прогноз y вне блока\n",
    "    Y_pred = \n",
    "    Y_hat = list()\n",
    "    for y_i in Y_pred : \n",
    "        Y_hat.append([i for i in range(len(y_i)) if y_i[i] == max(y_i)][0])\n",
    "    # считаем точность\n",
    "    acc = \n",
    "    acc_blocks.append(acc)\n",
    "\n",
    "score.append(np.around(np.mean(acc_blocks), 3))\n",
    "score_models.append('logit_PLS')\n",
    "print('Модель ', score_models[1], ', перекрёстная проверка по 10 блокам',\n",
    "      '\\nAcc = ', np.around(score[1], 2), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d46e811",
   "metadata": {},
   "source": [
    "# Методы сжатия  \n",
    "\n",
    "## Ридж-регрессия  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01d7f4",
   "metadata": {},
   "source": [
    "Функция `LogisticRegression()` умеет работать с мультиклассовой классификацией, используя при оценке параметров подход **один класс против остальных**. Построим ридж на наших данных.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b717e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для построения модели\n",
    "logit_ridge = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "# оцениваем параметры\n",
    "\n",
    "# выводим параметры\n",
    "print('Константы моделей для классов:\\n', ,\n",
    "     '\\nКоэффициенты моделей для классов:\\n', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89338159",
   "metadata": {},
   "source": [
    "Подбираем гиперпараметр регуляризации $\\lambda$ с помощью перекрёстной проверки. В функции \n",
    "`LogisticRegression()` есть аргумент $C$ – это инверсия гиперпараметра $\\lambda$.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиск оптимального значения C:\n",
    "#  подбираем C по наибольшей точности с перекрёстной проверкой\n",
    "ridge_cv = LogisticRegressionCV(cv=10, random_state=my_seed+2, \n",
    "                                penalty='l2', solver='liblinear')\n",
    "\n",
    "# значения параметра C (инверсия лямбды), которые дают наилучшую\n",
    "#  точность для каждого класса\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c84f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем и выводим Acc для модели\n",
    "score.append(np.around(ridge_cv.score(X_train_std, Y_train), 3))\n",
    "score_models.append('logit_ridge')\n",
    "print('Модель ', score_models[2], ', перекрёстная проверка по 10 блокам',\n",
    "      '\\nAcc = ', score[2], sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83226cc",
   "metadata": {},
   "source": [
    "Изобразим изменение коэффициентов ридж-регрессии на графике и сделаем отсечку на уровне оптимального параметра $C$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# график динамики коэффициентов в ридж-регрессии    \n",
    "#  модель для класса 0\n",
    "plot_coeffs_traces(X_train_std, Y_train, 0, 'l2', ridge_cv.C_, DF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd27494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# график динамики коэффициентов в ридж-регрессии    \n",
    "#  модель для класса 1\n",
    "plot_coeffs_traces(X_train_std, Y_train, 1, 'l2', ridge_cv.C_, DF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb296ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# график динамики коэффициентов в ридж-регрессии    \n",
    "#  модель для класса 2\n",
    "plot_coeffs_traces(X_train_std, Y_train, 2, 'l2', ridge_cv.C_, DF.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a02626",
   "metadata": {},
   "source": [
    "## Лассо-регрессия\n",
    "\n",
    "Технически реализация лассо-регрессии отличается от ридж единственным аргументом `penalty='l1'` в функции `LogisticRegression`.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для построения модели\n",
    "logit_lasso = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "# оцениваем параметры\n",
    "logit_lasso.fit(X_train_std, Y_train)\n",
    "# выводим параметры\n",
    "print('Константы моделей для классов:\\n', np.around(logit_lasso.intercept_, 3),\n",
    "     '\\nКоэффициенты моделей для классов:\\n', np.around(logit_lasso.coef_, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd8cfb4",
   "metadata": {},
   "source": [
    "Отметим, что в векторе коэффициентов появились нулевые значения: метод лассо позволяет обнулять коэффициенты, тем самым отбрасывая слабые объясняющие переменные.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a80a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# поиск оптимального значения C:\n",
    "#  подбираем C по наибольшей точности с перекрёстной проверкой\n",
    "lasso_cv = LogisticRegressionCV(cv=10, random_state=my_seed+3,\n",
    "                               penalty='l1', solver='liblinear')\n",
    "lasso_cv.fit(X_train_std, Y_train)\n",
    "# значения параметра C (инверсия лямбды), которые дают наилучшую\n",
    "#  точность для каждого класса\n",
    "lasso_cv.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae71683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем и выводим Acc для модели\n",
    "score.append(np.around(lasso_cv.score(X_train_std, Y_train), 3))\n",
    "score_models.append('logit_lasso')\n",
    "print('Модель ', score_models[3], ', перекрёстная проверка по 10 блокам',\n",
    "      '\\nAcc = ', score[3], sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15ed701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# график динамики коэффициентов в лассо-регрессии    \n",
    "#  модель для класса 0\n",
    "plot_coeffs_traces(X_train_std, Y_train, 0, 'l1', lasso_cv.C_, DF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16638c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# график динамики коэффициентов в лассо-регрессии    \n",
    "#  модель для класса 1\n",
    "plot_coeffs_traces(X_train_std, Y_train, 1, 'l1', lasso_cv.C_, DF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3739008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# график динамики коэффициентов в лассо-регрессии    \n",
    "#  модель для класса 2\n",
    "plot_coeffs_traces(X_train_std, Y_train, 2, 'l1', lasso_cv.C_, DF.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041010d5",
   "metadata": {},
   "source": [
    "Итак, судя по графикам, для значения гиперпараметра, дающего самую точную модель, ни один коэффициент при объясняющих переменных не обнуляется. Это подтверждает наблюдение, сделанное нами ещё на этапе предварительного анализа: все объясняющие переменные неплохо разделяют классы.   \n",
    "\n",
    "\n",
    "# Прогноз на отложенные наблюдения по лучшей модели\n",
    "\n",
    "Ещё раз посмотрим на точность построенных моделей.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f506f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сводка по точности моделей\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7c905",
   "metadata": {},
   "source": [
    "Все модели показывают высокую точность по показателю $Acc$, при этом самой точной оказывается ридж-регрессия. Сделаем прогноз на отложенные наблюдения.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# формируем объекты с данными отложенной выборки\n",
    "X_pred_std = \n",
    "Y_pred = \n",
    "Y_hat = \n",
    "# отчёт по точности на отложенных наблюдениях\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e4aa0a",
   "metadata": {},
   "source": [
    "Итак, методом логистической регрессии со сжатием коэффициенты с L2-регуляризацией мы получили идеально точную модель классификации трёх видов красных вин.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af39298f",
   "metadata": {},
   "source": [
    "# Источники \n",
    "\n",
    "1. *Рашка С.* Python и машинное обучение: крайне необходимое пособие по новейшей предсказательной аналитике, обязательное для более глубокого понимания методологии машинного обучения / пер. с англ. А.В. Логунова. – М.: ДМК Пресс, 2017. – 418 с.: ил.  \n",
    "1. Репозиторий с кодом к книге *Рашка С.* Python и машинное обучение / github.com. URL: <https://github.com/rasbt/python-machine-learning-book-3rd-edition>  \n",
    "1. *Xueting Bai*, *Lingbo Wang*, *Hanning Li* Identification of red wine categories based on physicochemical properties / 2019 5th International Conference on Education Technology, Management and Humanities Science (ETMHS 2019). URL: <https://webofproceedings.org/proceedings_series/ESSP/ETMHS%202019/ETMHS19309.pdf>  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
