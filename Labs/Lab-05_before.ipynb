{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b8b1c8d",
   "metadata": {},
   "source": [
    "`Дисциплина: Методы и технологии машинного обучения`   \n",
    "`Уровень подготовки: бакалавриат`   \n",
    "`Направление подготовки: 01.03.02 Прикладная математика и информатика`   \n",
    "`Семестр: осень 2021/2022`   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c915500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# настройка ширины страницы блокнота .......................................\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "# расширение watermark для вывода информации о версиях пакетов\n",
    "#  https://github.com/rasbt/watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc5c8ab",
   "metadata": {},
   "source": [
    "# Лабораторная работа №5: Методы, основанные на деревьях решений. Регрессионные деревья. Деревья классификации. Случайный лес. Бустинг.  \n",
    "\n",
    "В практических примерах ниже показано:   \n",
    "\n",
    "* как делать перекодировку признаков в номинальной и порядковой шкалах\n",
    "* как вырастить дерево и сделать обрезку его ветвей   \n",
    "* как настроить модель бэггинга   \n",
    "* как вырастить случайный лес  \n",
    "* как настроить модель бустинга на деревьях решений  \n",
    "* как подбирать настроечные параметры моделей методом сеточного поиска  \n",
    "\n",
    "Точность всех моделей оценивается методом перекрёстной проверки по 5 блокам.  \n",
    "\n",
    "*Модели*: дерево классификации, бэггинг, случайный лес, бустинг, дерево регрессии  \n",
    "*Данные*: `in-vehicle-coupon-recommendation.csv`. Источник: [сайт Калифорнийского университета в Ирвине](https://archive.ics.uci.edu/ml/datasets/in-vehicle+coupon+recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1dd899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводим информацию о версиях python и пакетов\n",
    "%watermark -a \"aksyuk@github.com\" -d -v -p numpy,pandas,matplotlib,sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9ab5d",
   "metadata": {},
   "source": [
    "# Указания к выполнению\n",
    "\n",
    "\n",
    "## Загружаем пакеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка пакетов: инструменты --------------------------------------------\n",
    "#  работа с массивами\n",
    "import numpy as np\n",
    "#  фреймы данных\n",
    "import pandas as pd\n",
    "#  графики\n",
    "import matplotlib as mpl\n",
    "#  стили и шаблоны графиков на основе matplotlib\n",
    "import seaborn as sns\n",
    "# загрузка файлов по URL\n",
    "import urllib\n",
    "# проверка существования файла на диске\n",
    "from pathlib import Path\n",
    "# для форматирования результатов с помощью Markdown\n",
    "from IPython.display import Markdown, display\n",
    "# перекодировка категориальных переменных\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "# хи-квадрат тест на независимость по таблице сопряжённости\n",
    "from scipy.stats import chi2_contingency\n",
    "#  для таймера\n",
    "import time\n",
    "\n",
    "# загрузка пакетов: данные -------------------------------------------------\n",
    "from sklearn import datasets\n",
    "\n",
    "# загрузка пакетов: модели -------------------------------------------------\n",
    "#  дерево классификации\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "# перекрёстная проверка и метод проверочной выборки\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "# для перекрёстной проверки и сеточного поиска\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "# бэггинг\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# случайный лес\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# бустинг\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#  сводка по точности классификации\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# константы\n",
    "#  ядро для генератора случайных чисел\n",
    "my_seed = 9212\n",
    "#  создаём псевдоним для короткого обращения к графикам\n",
    "plt = mpl.pyplot\n",
    "# настройка стиля и отображения графиков\n",
    "#  примеры стилей и шаблонов графиков: \n",
    "#  http://tonysyu.github.io/raw_content/matplotlib-style-gallery/gallery.html\n",
    "mpl.style.use('seaborn-whitegrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "# раскомментируйте следующую строку, чтобы посмотреть палитру\n",
    "# sns.color_palette(\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a2353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция форматирования результатов с использованием Markdown\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "# функции для попарной конкатенации элементов двух списков\n",
    "concat_func_md = lambda x, y: '`' + str(x) + \"`:&ensp;&ensp;&ensp;&ensp;\" + str(y)\n",
    "concat_func = lambda x, y: str(x) + ' ' * 4 + str(y)\n",
    "\n",
    "\n",
    "# функция, которая строит график важности признаков в модели случайного леса\n",
    "#  источник: https://www.analyseup.com/learn-python-for-data-science/python-random-forest-feature-importance-plot.html\n",
    "def plot_feature_importance(importance, names, model_type) :\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,\n",
    "                      inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title('Важность признаков в модели: ' + model_type)\n",
    "    plt.xlabel('Важность признака')\n",
    "    plt.ylabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87618f1b",
   "metadata": {},
   "source": [
    "## Загружаем данные\n",
    "\n",
    "Набор данных можно загрузить напрямую по ссылке: <https://raw.githubusercontent.com/aksyuk/MTML/main/Labs/data/in-vehicle-coupon-recommendation.csv>. Справочник к данным доступен по адресу: <https://github.com/aksyuk/MTML/blob/main/Labs/data/CodeBook_in-vehicle-coupon-recommendation.md>.    \n",
    "\n",
    "Загружаем данные во фрейм и выясняем их размерность. В таблице много строк, поэтому для экономии времени загрузку сделаем в два шага: сначала скачаем таблицу и сохраним в папку `'./data'`, затем прочитаем её во фрейм. Перед скачиванием проверим, нет ли уже такого файла в папке с данными.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e42f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# путь к локальному файлу для сохранения\n",
    "localFilePath = './data/in-vehicle-coupon-recommendation.csv'\n",
    "\n",
    "# проверяем, нет ли уже такого файла на диске\n",
    "\n",
    "    # загружаем таблицу и превращаем её во фрейм\n",
    "    fileURL = 'https://raw.githubusercontent.com/aksyuk/MTML/main/Labs/data/in-vehicle-coupon-recommendation.csv'\n",
    "    # скачиваем\n",
    "    \n",
    "    print('Файл', localFilePath,'успешно загружен с адреса ', fileURL, '\\n')\n",
    "else:\n",
    "    print('Файл', localFilePath,'уже есть на диске\\n')\n",
    "\n",
    "# читаем\n",
    "DF_raw = \n",
    "\n",
    "# выясняем размерность фрейма\n",
    "print('Число строк и столбцов в наборе данных:\\n', DF_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07670649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# типы столбцов\n",
    "DF_raw.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe68e45",
   "metadata": {},
   "source": [
    "Проблема в том, что, судя по справочнику к данным, все столбцы таблицы являются категориальными. Однако некоторые (бинарные) воспринимаются как `int`, а остальные как `object`. Посмотрим на столбцы типа `int`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca342e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# первые 7 строк столбцов типа int64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a443be",
   "metadata": {},
   "source": [
    "Функция построения дерева классификации `DecisionTreeClassifier()` требует числовых порядковых значений переменных. Видно, что столбцы типа `int64` либо порядковые (`temperature`), либо бинарные (все остальные), их преобразовывать нет необходимости. А вот столбцы типа `object` придётся кодировать вручную.  \n",
    "При этом на этапе предварительного анализа данных нам удобнее будет работать с исходными категориальными столбцами. Поэтому сейчас просто изменим тип столбцов `object` на `category`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# меняем тип столбцов на категориальные\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7ffd1",
   "metadata": {},
   "source": [
    "Отложим 30% наблюдений для прогноза.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f9300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# наблюдения для моделирования\n",
    "DF = \n",
    "# отложенные наблюдения\n",
    "DF_predict = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1635163a",
   "metadata": {},
   "source": [
    "# Предварительный анализ данных  \n",
    "\n",
    "## Описательные статистики  \n",
    "\n",
    "Стандартный подсчёт статистик с помощью фунции `describe()` бесполезен для категориальных столбцов, поэтому рассчитаем частоты категорий по каждому столбцу. Для вывода отчёта воспользуемся форматированием на Markdown.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78108987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем частоты по столбцам, учитывая пропуски\n",
    "for col in DF.columns:\n",
    "    freq_col = \n",
    "    str_freqs = \n",
    "    str_names = \n",
    "    # для вывода в html\n",
    "    printmd('**' + col + '**</br>' + \n",
    "            '</br>'.join(list(map(concat_func_md, str_names, str_freqs))))\n",
    "    # для сохранения в pdf\n",
    "    # print('\\n', col, '\\n', \n",
    "    #       '\\n'.join(list(map(concat_func, str_names, str_freqs))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78dc0a",
   "metadata": {},
   "source": [
    "Обратим внимание на столбцы `car` и `toCoupon_GEQ5min`, которые есть в таблице, но отсутствовали в справочнике к данным. В первом (тип автомобиля) пропущено 99,1% наблюдений, во втором (до ресторана/кофейни, в которую выдан купон, более 5 минут езды) значения во всех наблюдениях одинаковы. Уберём эти столбцы из обучающих и отложенных данных.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa27da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбрасываем стобцы с большинством пропусков или с нулевой дисперсией\n",
    "#  из обучающей выборки\n",
    "DF = \n",
    "#  и из отложенных наблюдений\n",
    "DF_predict = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a540a2",
   "metadata": {},
   "source": [
    "Ещё раз оценим количество пропусков.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a96cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем пропуски в столбцах, выводим ненулевые значения\n",
    "nas = DF.isna().sum()\n",
    "nas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b618a25b",
   "metadata": {},
   "source": [
    "Подсчитаем, сколько наблюдений мы потеряем, если выбросим все строки хотя бы с одним пропуском.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca66ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_rows = sum([True for idx, row in DF.iterrows() if any(row.isnull())])\n",
    "print('Из-за пропусков пропадает ', na_rows, ' строк (',\n",
    "      np.around(na_rows / DF.shape[0] * 100, 1), '%)', sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe7bbef",
   "metadata": {},
   "source": [
    "Выводы по описательным статистикам: доли классов (`Y`) сопоставимы, наибольшее количество категорий у объясняющей переменной `occupation`. Строки с пропусками составляют не более 5%, поэтому мы уберём их из обучающей выборки.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46535798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выкидываем пропуски из обучащей\n",
    "DF = \n",
    "DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec13491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выкидываем пропуски из отложенных наблюдений\n",
    "DF_predict = \n",
    "DF_predict.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8992461",
   "metadata": {},
   "source": [
    "## Распределение предикторов внутри классов  по зависимой переменной\n",
    "\n",
    "Все объясняющие переменные являются категориальными, поэтому оценивать их связь с зависимой переменной с помощью корреляционной матрицы некорректно. Вместо этого можно воспользоваться [критерием согласия Хи-квадрат](https://ru.wikipedia.org/wiki/%D0%9A%D1%80%D0%B8%D1%82%D0%B5%D1%80%D0%B8%D0%B9_%D1%81%D0%BE%D0%B3%D0%BB%D0%B0%D1%81%D0%B8%D1%8F_%D0%9F%D0%B8%D1%80%D1%81%D0%BE%D0%BD%D0%B0), который рассчитывается по таблице сопряжённости. Нулевая гипотеза теста: распределение долей в таблице сопряжённости случайно, т.е. два показателя независимы друг от друга.     \n",
    "Проведём тест для всех пар \"объясняющая переменная\" – \"зависимая переменная\" и выведем те пары, для которых соответствующее критерию p-значение больше 0.05 (т.е. нулевая гипотеза принимается, переменные независимы).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14078cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in DF.columns[:24] :\n",
    "    con_tab = \n",
    "    c, p, dof, expected = \n",
    "    if p > 0.05 :\n",
    "        print(col, 'и Y',\n",
    "              '\\nH_0: переменные распределены независимо друг от друга', \n",
    "              '\\nP-значение:', np.around(p, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d21a27",
   "metadata": {},
   "source": [
    "Интересный результат: полное совпадение p-значений – объясняется тем, что на самом деле `direction_same` и `direction_opp` противоположны друг другу. Связь между ними функциональная: если направление на ресторан/кофейню, в который предлагается купон, не совпадает с направлением на исходное место назначения (`direction_same == 0`), то оно противоположно (`direction_opp == 1`), и наоборот. Поэтому в модель имеет смысл включать только одну из этих переменных.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae7ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# исключаем direction_opp \n",
    "#  из обучающей выборки\n",
    "DF = DF.drop(['direction_opp'], axis=1)\n",
    "#  и из отложенных наблюдений\n",
    "DF_predict = DF_predict.drop(['direction_opp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04137e37",
   "metadata": {},
   "source": [
    "## Перекодировка номинальной и порядковой шкалы   \n",
    "\n",
    "Теперь перекодируем признаки так, чтобы воспользоваться функцией классификации на дереве решений. Начнём с тех, которые содержат признаки в номинальной шкале (между позициями нет отношения порядка). Перекодируем их в фиктивные с помощью функции `OneHotEncoder()`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d642fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# имена столбцов с номинальными показателями\n",
    "nom_col_names = ['destination', 'passanger', 'weather', 'coupon', 'gender', \n",
    "                 'maritalStatus', 'occupation']\n",
    "\n",
    "# создаём объект кодировщика\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# кодируем, результат – массив\n",
    "recoded = \n",
    "\n",
    "# создаём из результата новый фрейм с фиктивными переменными\n",
    "clmns = \n",
    "df_dummy_nom = \n",
    "\n",
    "# выводим размерность итога\n",
    "print(df_dummy_nom.shape)\n",
    "\n",
    "# смотрим результат\n",
    "df_dummy_nom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785adb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# исходник для сравнения\n",
    "print(DF[nom_col_names].shape)\n",
    "DF[nom_col_names].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b387cde3",
   "metadata": {},
   "source": [
    "Теперь разбираемся с показателями в порядковой шкале. Для этого воспользуемся `OrdinalEncoder()`. Для начала убедимся, что на этапе исключения пропущенных всё прошло штатно, и значений `'nan'`, которые `OrdinalEncoder()` не умеет обрабатывать, не осталось.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# имена столбцов с порядковыми показателями\n",
    "ord_col_names = ['time', 'expiration', 'age', 'education', 'income', \n",
    "                 'Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20',\n",
    "                 'Restaurant20To50']\n",
    "\n",
    "# считаем пропуски в столбцах\n",
    "for col in ord_col_names :\n",
    "    print('Пропусков в столбце', col, ':',\n",
    "          sum(DF[col].isnull().astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3711f90c",
   "metadata": {},
   "source": [
    "Всё отлично, пропусков нет, поэтому можно перекодировать все порядковые столбцы в одно действие.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаём списки с порядком кодировки для каждого столбца\n",
    "enc_time = ['7AM', '10AM', '2PM', '6PM', '10PM']\n",
    "enc_expiration = ['2h', '1d']\n",
    "enc_age = ['below21', '21', '26', '31', '36', '41', '46', '50plus']\n",
    "enc_education = ['Some High School', 'High School Graduate', \n",
    "                 'Some college - no degree', 'Associates degree',\n",
    "                 'Bachelors degree', \n",
    "                 'Graduate degree (Masters or Doctorate)']\n",
    "enc_income = ['Less than $12500', '$12500 - $24999', '$25000 - $37499',\n",
    "              '$37500 - $49999', '$50000 - $62499', '$62500 - $74999',\n",
    "             '$75000 - $87499', '$87500 - $99999', '$100000 or More']\n",
    "enc_how_often = ['never', 'less1', '1~3', '4~8', 'gt8']\n",
    "\n",
    "# перекодировщик\n",
    "ordinal = \n",
    "\n",
    "# кодируем\n",
    "df_ord = \n",
    "\n",
    "# выводим размерность итога\n",
    "print(df_ord.shape)\n",
    "\n",
    "# результат\n",
    "df_ord.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# исходник для сравнения\n",
    "print(DF[ord_col_names].shape)\n",
    "DF[ord_col_names].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435bc56c",
   "metadata": {},
   "source": [
    "Объединим результаты: исходно числовые столбцы, дамми для признаков в номинальной шкале и перекодированные признаки в порядковой шкале – во фрейм под названием `DF_num`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c489fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем результаты перекодировки в один фрейм\n",
    "DF_num = \n",
    "\n",
    "\n",
    "print('Размерность обучающего фрейма после исключения NaN',\n",
    "      '\\nи перекодировки: ', DF_num.shape)\n",
    "\n",
    "# результат\n",
    "DF_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f9e16",
   "metadata": {},
   "source": [
    "Повторяем перекодировку для фрейма с отложенными наблюдениями `DF_predict`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7746004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# перекодировка отложенных наблюдений\n",
    "#  номинальная шкала -------------------------------------------------------\n",
    "#   кодируем, результат – массив\n",
    "recoded = one_hot.fit_transform(DF_predict[nom_col_names]).toarray()\n",
    "\n",
    "# создаём из результата новый фрейм с фиктивными переменными\n",
    "clmns = one_hot.get_feature_names(nom_col_names)\n",
    "df_dummy_nom = pd.DataFrame(recoded, columns=clmns)\n",
    "\n",
    "#  порядковая шкала --------------------------------------------------------\n",
    "#   кодируем\n",
    "df_ord = pd.DataFrame(ordinal.fit_transform(DF_predict[ord_col_names]), \n",
    "                        columns = ord_col_names)\n",
    "\n",
    "#   объединяем результаты\n",
    "DF_predict_num = pd.concat([DF_predict.loc[:, \n",
    "    DF_predict.dtypes == 'int64'].reset_index(), \n",
    "                            df_dummy_nom, df_ord], axis=1)\n",
    "\n",
    "print('Размерность фрейма с отложенными наблюдениями после исключения NaN',\n",
    "      '\\nи перекодировки: ', DF_predict_num.shape)\n",
    "\n",
    "# результат\n",
    "DF_predict_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a48810",
   "metadata": {},
   "source": [
    "# Модель дерева  \n",
    "\n",
    "В этом разделе построим:  \n",
    "\n",
    "* дерево классификации  \n",
    "* дерево классификации с обрезкой ветвей  \n",
    "\n",
    "\n",
    "## Дерево на всех признаках    \n",
    "\n",
    "Построим модель и выведем изображение дерева в виде текста.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688312d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выращиваем дерево на всех объясняющих\n",
    "X = \n",
    "y = \n",
    "\n",
    "# классификатор\n",
    "cls_one_tree = \n",
    "\n",
    "tree_full = \n",
    "\n",
    "# выводим количество листьев (количество узлов)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce2b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# глубина дерева: количество узлов от корня до листа\n",
    "#  в самой длинной ветви\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa61de0",
   "metadata": {},
   "source": [
    "Очевидно, дерево получилось слишком большое для отображения в текстовом формате. Графическая визуализация тоже не поможет в данном случае. Посчитаем показатели точности с перекрёстной проверкой.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0127bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# будем сохранять точность моделей в один массив:\n",
    "score = list()\n",
    "score_models = list()\n",
    "\n",
    "# считаем точность с перекрёстной проверкой, показатель Acc\n",
    "cv = \n",
    "\n",
    "\n",
    "# записываем точность\n",
    "score.append(np.around(np.mean(cv), 3))\n",
    "score_models.append('one_tree')\n",
    "\n",
    "print('Acc с перекрёстной проверкой',\n",
    "      '\\nдля модели', score_models[0], ':', score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a2df5",
   "metadata": {},
   "source": [
    "## Дерево с обрезкой ветвей   \n",
    "\n",
    "Подберём оптимальное количество ветвей, которое максимизирует $Acc$, для экономии времени рассчитанный методом проверочной выборки.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2935464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассчитываем параметры alpha для эффективных вариантов обрезки ветвей\n",
    "path = \n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "print('Всего значений alpha:', len(ccp_alphas))\n",
    "print('Энтропия листьев для первых 5 значений alpha:', impurities[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# изображаем на графике\n",
    "plt.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\n",
    "plt.xlabel(\"значение гиперпараметра alpha\")\n",
    "plt.ylabel(\"общая энтропия листьев дерева\")\n",
    "plt.title(\"Изменение показателя нечистоты узлов с ростом alpha\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3276234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучающая и тестовая выборки, чтобы сэкономить время\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    random_state=my_seed)\n",
    "\n",
    "# модели\n",
    "clfs = list()\n",
    "\n",
    "# таймер\n",
    "tic = time.perf_counter()\n",
    "# цикл по значениям alpha\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = \n",
    "    \n",
    "    \n",
    "\n",
    "# таймер\n",
    "toc = time.perf_counter()\n",
    "print(f\"Расчёты по обрезке дерева заняли {toc - tic:0.2f} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33434419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлекаем характеристики глубины и точности\n",
    "#  таймер\n",
    "tic = time.perf_counter()\n",
    "node_counts = \n",
    "train_scores = \n",
    "test_scores = \n",
    "#  таймер\n",
    "toc = time.perf_counter()\n",
    "print(f\"Расчёты показателей точности заняли {toc - tic:0.2f} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f502a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# изображаем на графике\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "# график глубины дерева\n",
    "ax[0].plot(ccp_alphas, node_counts, marker=',', drawstyle=\"steps-post\")\n",
    "ax[0].set_xlabel(\"значение гиперпараметра alpha\")\n",
    "ax[0].set_ylabel(\"количество узлов\")\n",
    "ax[0].set_title(\"Сложность модели vs alpha\")\n",
    "\n",
    "# график точности\n",
    "ax[1].plot(ccp_alphas, train_scores, marker=',', label='train',\n",
    "           drawstyle=\"steps-post\")\n",
    "ax[1].plot(ccp_alphas, test_scores, marker=',', label='test',\n",
    "           drawstyle=\"steps-post\")\n",
    "ax[1].set_xlabel(\"значение гиперпараметра alpha\")\n",
    "ax[1].set_ylabel(\"Acc\")\n",
    "ax[1].set_title(\"Точность модели  vs alpha\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42254d2b",
   "metadata": {},
   "source": [
    "Находим оптимальный размер дерева по максимуму $Acc$ на тестовой выборке.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22746203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# оптимальное количество узлов\n",
    "opt_nodes_num = \n",
    "\n",
    "# считаем точность с перекрёстной проверкой, показатель Acc\n",
    "cv = \n",
    "\n",
    "# записываем точность\n",
    "score.append(np.around(np.mean(cv), 3))\n",
    "score_models.append('pruned_tree')\n",
    "\n",
    "print('Оптимальное количество узлов:', opt_nodes_num,\n",
    "      '\\nсоответствующая Acc на тествоой:', np.around(max(test_scores), 3),\n",
    "      '\\n\\nAcc с перекрёстной проверкой',\n",
    "      '\\nдля модели', score_models[1], ':', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be66ffe3",
   "metadata": {},
   "source": [
    "Посмотрим на характеристики глубины и сложности построенного дерева с обрезкой ветвей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d36d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводим количество листьев (количество узлов)\n",
    "clfs[opt_nodes_num].get_n_leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be182d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# глубина дерева: количество узлов от корня до листа\n",
    "#  в самой длинной ветви\n",
    "clfs[opt_nodes_num].get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d3d3e8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "📚 **Пример визуализации небольшого дерева**\n",
    "\n",
    "Лучшее дерево с обрезкой по-прежнему слишком велико для визуализации. Для примера нарисуем одно из небольших деревьев с обрезкой и выведем его же в виде текста.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# находим деревья с количеством листьев меньше 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# визуализация на схеме НА ПРИМЕРЕ МАЛЕНЬКОГО ДЕРЕВА\n",
    "nodes_num = \n",
    "print('Количество узлов:', nodes_num,\n",
    "      '\\nТочность дерева на тестовой:', \n",
    "      np.around(test_scores[node_counts.index(nodes_num)], 3))\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = plot_tree(, \n",
    "              filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46adc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# визуализируем дерево в виде текстовой схемы\n",
    "viz = export_text(, \n",
    "                  feature_names=list(X.columns))\n",
    "print(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a0c22",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Бэггинг  \n",
    "\n",
    "Модель бэггинга использует бутстреп, чтобы вырастить $B$ деревьев на выборках с повторами из обучающих данных. Построим модель для $B=50$ деревьев.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e2e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметр B: количество деревьев\n",
    "num_trees = 50\n",
    "\n",
    "# разбиения для перекрёстной проверки\n",
    "kfold = \n",
    "\n",
    "# таймер\n",
    "tic = time.perf_counter()\n",
    "# модель с бэггингом\n",
    "tree_bag = \n",
    "\n",
    "cv = \n",
    "\n",
    "# таймер\n",
    "toc = time.perf_counter()\n",
    "print(f\"Обучение модели с бэггингом на {num_trees:0.0f} деревьях\", \n",
    "      \" и перекрёстной проверкой \", \n",
    "      f\"заняло {toc - tic:0.2f} секунд\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# точность\n",
    "np.around(np.mean(cv), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7ecbf3",
   "metadata": {},
   "source": [
    "Итак, мы построили модель, выбрав параметр $B$ случайным образом. Воспользуемся функцией `GridSearchCV()`, чтобы перебрать 5 вариантов значений для параметра $B$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0895547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# настроим параметры бэггинга с помощью сеточного поиска\n",
    "param_grid = \n",
    "\n",
    "# таймер\n",
    "tic = time.perf_counter()\n",
    "clf = \n",
    "\n",
    "tree_bag = \n",
    "# таймер\n",
    "toc = time.perf_counter()\n",
    "print(f\"Сеточный поиск занял {toc - tic:0.2f} секунд\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d14e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# точность лучшей модели\n",
    "np.around(, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bc0aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество деревьев у лучшей модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b835b",
   "metadata": {},
   "source": [
    "Таким образом, перебрав несколько вариантов для $B$, мы немного улучшили первоначальную точность модели бэггинга.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# записываем точность\n",
    "score.append(np.around(tree_bag.best_score_, 3))\n",
    "score_models.append('bagging_GS')\n",
    "\n",
    "print('Acc с перекрёстной проверкой',\n",
    "      '\\nдля модели', score_models[2], ':', score[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c555295",
   "metadata": {},
   "source": [
    "# Случайный лес  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d0eb85",
   "metadata": {},
   "source": [
    "У модели случайного леса два настроечных параметра: количество деревьев $B$ и количество признаков для построения отдельного дерева $m$. Настроим сеточный поиск для их подбора.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9f29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сколько столбцов в обучающих данных (p)\n",
    "X_m = X.shape[1]\n",
    "# возьмём значения для m: p, p/2, sqrt(p) и log2(p)\n",
    "ms = np.around([X_m, X_m / 2, np.sqrt(X_m), np.log2(X_m)]).astype(int)\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab38083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# настроим параметры случайного леса с помощью сеточного поиска\n",
    "param_grid = {'n_estimators' : [10, 20, 30, 40, 50],\n",
    "              'max_features' : ms}\n",
    "\n",
    "# таймер\n",
    "tic = time.perf_counter()\n",
    "clf = GridSearchCV(RandomForestClassifier(DecisionTreeClassifier()),\n",
    "                   param_grid, scoring='accuracy', cv=kfold)\n",
    "random_forest = clf.fit(X, y)\n",
    "# таймер\n",
    "toc = time.perf_counter()\n",
    "print(f\"Сеточный поиск занял {toc - tic:0.2f} секунд\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f92a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# точность лучшей модели\n",
    "np.around(random_forest.best_score_, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac693c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество деревьев у лучшей модели\n",
    "random_forest.best_estimator_.get_params()['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e1517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество объясняющих у лучшей модели\n",
    "random_forest.best_estimator_.get_params()['max_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2dc3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# рисуем график относительной важности каждого признака\n",
    "plot_feature_importance(random_forest.best_estimator_.feature_importances_,\n",
    "                        X.columns, 'Случайный лес')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ebeefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# записываем точность\n",
    "score.append(np.around(random_forest.best_score_, 3))\n",
    "score_models.append('random_forest_GS')\n",
    "\n",
    "print('Acc с перекрёстной проверкой',\n",
    "      '\\nдля модели', score_models[3], ':', score[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d46e811",
   "metadata": {},
   "source": [
    "# Бустинг \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad6909e",
   "metadata": {},
   "source": [
    "Подберём сеточным поиском настроечные параметры модели:  \n",
    "* $B$ число деревьев, \n",
    "* $\\lambda$ – скорость обучения,\n",
    "* $d$ – глубина взаимодействия предикторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучаем модель с параметрами по умолчанию\n",
    "clf_tst = \n",
    "cv = cross_val_score(clf_tst, X, y, cv=kfold, scoring='accuracy')\n",
    "np.around(np.mean(cv), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b717e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# настроим параметры бустинга с помощью сеточного поиска\n",
    "param_grid = {'n_estimators' : [10, 20, 30, 40, 50],\n",
    "              'learning_rate' : np.linspace(start=0.01, stop=0.25, num=15),\n",
    "              'max_depth' : [1, 2]}\n",
    "\n",
    "# таймер\n",
    "tic = time.perf_counter()\n",
    "clf = GridSearchCV(GradientBoostingClassifier(),\n",
    "                   param_grid, scoring='accuracy', cv=kfold)\n",
    "boost_tree = clf.fit(X, y)\n",
    "# таймер\n",
    "toc = time.perf_counter()\n",
    "print(f\"Сеточный поиск занял {toc - tic:0.2f} секунд\", sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a80be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# точность лучшей модели\n",
    "np.around(boost_tree.best_score_, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметры лучшей модели\n",
    "print('n_estimators:', \n",
    "      boost_tree.best_estimator_.get_params()['n_estimators'],\n",
    "      '\\nlearning_rate:',\n",
    "      boost_tree.best_estimator_.get_params()['learning_rate'],\n",
    "      '\\nmax_depth:',\n",
    "      boost_tree.best_estimator_.get_params()['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4436a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# записываем точность\n",
    "score.append(np.around(boost_tree.best_score_, 3))\n",
    "score_models.append('boost_tree_GS')\n",
    "\n",
    "print('Acc с перекрёстной проверкой',\n",
    "      '\\nдля модели', score_models[4], ':', score[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041010d5",
   "metadata": {},
   "source": [
    "\n",
    "# Прогноз на отложенные наблюдения по лучшей модели\n",
    "\n",
    "Ещё раз посмотрим на точность построенных моделей.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f506f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сводка по точности моделей\n",
    "pd.DataFrame({'Модель' : score_models, 'Acc' : score})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7c905",
   "metadata": {},
   "source": [
    "Все модели показывают среднюю точность по показателю $Acc$, при этом самой точной оказывается модель случайного леса. Сделаем прогноз на отложенные наблюдения.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# данные для прогноза\n",
    "X_pred = \n",
    "# строим прогноз\n",
    "y_hat = \n",
    "# характеристики точности\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af39298f",
   "metadata": {},
   "source": [
    "# Источники \n",
    "\n",
    "1. Джеймс Г., Уиттон Д., Хасти Т., Тибширани Р. Введение в статистическое обучение с примерами на языке R. Пер. с англ. С.Э. Мастицкого – М.: ДМК Пресс, 2016 – 450 с.  \n",
    "1. *Рашка С.* Python и машинное обучение: крайне необходимое пособие по новейшей предсказательной аналитике, обязательное для более глубокого понимания методологии машинного обучения / пер. с англ. А.В. Логунова. – М.: ДМК Пресс, 2017. – 418 с.: ил.  \n",
    "1. *Tong Wang*, *Cynthia Rudin*, *Finale Doshi-Velez*, *Yimin Liu*, *Erica Klampfl*, *Perry MacNeille* A Bayesian Framework for Learning Rule Sets for Interpretable Classification / Journal of Machine Learning Research 18 (2017) 1-37. URL: <https://jmlr.org/papers/volume18/16-003/16-003.pdf>  \n",
    "1. *George Pipis* How to Run the Chi-Square Test in Python / medium.com. URL: <https://medium.com/swlh/how-to-run-chi-square-test-in-python-4e9f5d10249d>   \n",
    "1. *Bernd Klein* What are Decision Trees? / python-course.eu. URL: <https://www.python-course.eu/Decision_Trees.php>  \n",
    "1. Pruning decision trees - tutorial / kaggle.com. URL: <https://www.kaggle.com/arunmohan003/pruning-decision-trees-tutorial>  \n",
    "1. Post pruning decision trees with cost complexity pruning / scikit-learn.org. URL: <https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html>  \n",
    "1. *Piotr Płoński* Visualize a Decision Tree in 4 Ways with Scikit-Learn and Python / mljar.com. URL: <https://mljar.com/blog/visualize-decision-tree/>  \n",
    "1. Random Forest Feature Importance Plot / www.analyseup.com. URL: <https://www.analyseup.com/learn-python-for-data-science/python-random-forest-feature-importance-plot.html>  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
